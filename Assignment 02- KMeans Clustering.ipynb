{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 02: K-Means Clustering\n",
    "\n",
    "I want you to implement a function to calculate the k-means clustering of a dataframe of $m$ observations with $n$ attributes.\n",
    "\n",
    "Your implementation function should have the signature:\n",
    "    \n",
    "    cluster_kmeans(df, k)\n",
    "    \n",
    "where\n",
    "    \n",
    "    df is a Pandas dataframe of m observations with n attributes; m rows with n columns (excluding index;\n",
    "    the index will contain the label for each observation and is not considered an attribute)\n",
    "    \n",
    "    k is the number of clusters to find\n",
    "\n",
    "The function should return a new dataframe with a single column: the cluster label for each observation.\n",
    "(Copy the index from the input dataframe into the output dataframe to keep them consistent.).  It should also return the last Sum-of-the-Square-Errors (SSE) from the clustering.\n",
    "\n",
    "For the proximity measure, you can use Euclidean distance as the metric.  Sum-of-the-Square-Errors is the objective function.  You can assume that the attributes have been standardized (i.e. properly-transformed) prior to k-means being called.\n",
    "\n",
    "**Keep your final solution notebook tidy.  I will be testing your code by first executing every cell in the notebook and then calling your `cluster_kmeans` with my test data.  If a cell cause the interpreter to throw an exception, I will not be able to test the notebook.**\n",
    "\n",
    "You may write additional functions and tests in this notebook to write and test your solution. *I should be able to add a cell at the end of this notebook and have it test your function by using  the kernel's \"Restart and Run All\" feature.*\n",
    "\n",
    "Start by creating test dataframes where the clusters should be obvious.  Then test the end of the process by being able to plot a dataframe's attributes on a 2D plot with the correct cluster label.  (Since these are test points, you know what that label should be.)  Once you know you can generate test data and plot the solution, begin working on the cluster_kmean's function.  \n",
    "\n",
    "After playing with a small number of points in test dataframes to check your solution, you may consider using [distribution sampling functions from numpy](https://docs.scipy.org/doc/numpy-1.14.0/reference/routines.random.html) to generate points in a cluster for testing.  (Combine the clusters you generate into a single dataframe to test how well your algorithm works.)\n",
    "\n",
    "Do note that the labels from each call to cluster_kmeans may change: that is cluster 1 and cluster 2 might appear as cluster 2 and cluster 1.  Since you know the original labels from your test data as you generated it yourself, you should be able to figure out which belongs to which original label during testing.\n",
    "\n",
    "**<span style=\"color:purple\">The project will be due after Spring break on Wednesday, March 11th @ 10PM via Mimir Classroom.</span>**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def cluster_kmeans(df, k):\n",
    "    \"\"\"\n",
    "    Clusters the m observations of n attributes \n",
    "    in the Pandas' dataframe df into k clusters.\n",
    "    \n",
    "    Euclidean distance is used as the proximity metric.\n",
    "    \n",
    "    Arguments:\n",
    "        df   pandas dataframe of m rows with n columns (excluding index)\n",
    "        k    the number of clusters to search for\n",
    "        \n",
    "    Returns:\n",
    "        a m x 1 dataframe of cluster labels for each of the m observations\n",
    "        retaining the original dataframe's (df's) index\n",
    "        \n",
    "        the final Sum-of-Error-Squared (SSE) from the clustering\n",
    "    \"\"\"\n",
    "    # Sample fron the original df\n",
    "    sample_df=df.sample(n = k)\n",
    "    obs, attr= df.shape\n",
    "    # Make copies \n",
    "    copy_df=df.copy()\n",
    "    flag=0\n",
    "    sse_old=0\n",
    "    while (flag==0): \n",
    "        sse=0\n",
    "        Labels=[]\n",
    "        for i in range(0, obs):\n",
    "            dist= []\n",
    "            for j in range(0,k):\n",
    "                #Calculate Eucledian distance\n",
    "                diff=list((df.iloc[i,:]-sample_df.iloc[j,:])**2)\n",
    "                eu_dist=(sum(diff))**(1/attr)\n",
    "                dist.append(eu_dist) \n",
    "            #Add Labels to the observations based on the variable they are close to\n",
    "            label=(dist.index(min(dist)))\n",
    "            Labels.append(label)\n",
    "            # Calculate SSE\n",
    "            sse=sse+((min(dist) )**2)\n",
    "        sse=sse**(1/2)\n",
    "        copy_df['Labels']=Labels\n",
    "        # Stopping criteria is change in SSE should be 2 %\n",
    "        if (sse_old !=0):\n",
    "            if(abs(sse_old-sse)/sse_old<=0.02):\n",
    "                flag=1 \n",
    "                return (copy_df['Labels'].to_frame(), sse)\n",
    "            else:\n",
    "                sse_old=sse\n",
    "                sample_df.drop(sample_df.index, inplace=True)\n",
    "                # Now pick random values from each label and add it to the sample df\n",
    "                for val in range(0,k):\n",
    "                    sample_df = pd.concat([sample_df, copy_df[copy_df['Labels']==val].iloc[:,0:attr].sample(n=1)])\n",
    "        else:\n",
    "            sse_old=sse\n",
    "            sample_df.drop(sample_df.index, inplace=True)\n",
    "            for val in range(0,k):\n",
    "                sample_df = pd.concat([sample_df, copy_df[copy_df['Labels']==val].iloc[:,0:attr].sample(n=1)])\n",
    "        #copy_df.plot.scatter(copy_df.columns[0],copy_df.columns[1], c='Labels' ,colormap='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
